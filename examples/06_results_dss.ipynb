{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Results and DSS Operations\n",
    "\n",
    "This notebook demonstrates DSS file operations and results extraction:\n",
    "\n",
    "| Class | Purpose |\n",
    "|-------|--------|\n",
    "| `HmsDss` | Low-level DSS file operations (catalog, read, write) |\n",
    "| `HmsResults` | High-level results extraction (peak flows, hydrographs, volumes) |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "DSS operations require:\n",
    "- Java 8+ JDK/JRE installed\n",
    "- `pyjnius` package (`pip install pyjnius`)\n",
    "\n",
    "The HEC Monolith libraries are auto-downloaded on first use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hms-commander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "**For Development**: If working on hms-commander source code, use the `hmscmdr_local` conda environment (editable install) instead of pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from hms_commander import (\n",
    "    HmsExamples,\n",
    "    init_hms_project,\n",
    "    HmsCmdr,\n",
    "    HmsDss,\n",
    "    HmsResults\n",
    ")\n",
    "\n",
    "print(\"hms-commander loaded\")\n",
    "\n",
    "# Check if DSS operations are available\n",
    "dss_available = HmsDss.is_available()\n",
    "print(f\"DSS operations available: {dss_available}\")\n",
    "\n",
    "if not dss_available:\n",
    "    print(\"\\nNote: DSS operations require Java and pyjnius.\")\n",
    "    print(\"Install with: pip install pyjnius\")\n",
    "    print(\"Ensure JAVA_HOME is set to a Java 8+ JDK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. Extract Example Project and Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tifton example project\n",
    "project_path = HmsExamples.extract_project(\n",
    "    \"tifton\",\n",
    "    output_path=Path.cwd() / 'hms_example_projects' / 'tifton_results_dss'\n",
    ")\n",
    "\n",
    "print(f\"Project extracted to: {project_path}\")\n",
    "\n",
    "# Initialize project\n",
    "hms = init_hms_project(project_path)\n",
    "print(f\"\\nProject: {hms.project_name}\")\n",
    "print(f\"Available runs: {hms.list_run_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a run to generate DSS results (if needed)\n",
    "run_name = hms.list_run_names()[0]\n",
    "dss_file = hms.get_run_dss_file(run_name)\n",
    "\n",
    "print(f\"Run: {run_name}\")\n",
    "print(f\"DSS file: {dss_file}\")\n",
    "print(f\"DSS exists: {dss_file.exists() if dss_file else False}\")\n",
    "\n",
    "# Run HMS if DSS doesn't exist\n",
    "if dss_file and not dss_file.exists():\n",
    "    print(f\"\\nExecuting {run_name} to generate DSS results...\")\n",
    "    try:\n",
    "        result = HmsCmdr.compute_run(run_name, hms_object=hms)\n",
    "        if result.success:\n",
    "            print(f\"[OK] Completed in {result.execution_time:.1f}s\")\n",
    "        else:\n",
    "            print(f\"[FAILED] {result.error_message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] HMS execution not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. DSS File Information\n",
    "\n",
    "Get metadata about the DSS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    # Get DSS file info\n",
    "    info = HmsDss.get_info(str(dss_file))\n",
    "    \n",
    "    print(\"DSS File Information:\")\n",
    "    print(\"=\" * 60)\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"DSS file not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. DSS Catalog Exploration\n",
    "\n",
    "The catalog lists all pathnames (data records) in the DSS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    # Get DSS catalog\n",
    "    catalog = HmsDss.get_catalog(str(dss_file))\n",
    "    \n",
    "    print(f\"DSS Catalog ({len(catalog)} pathnames):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show first 15 pathnames\n",
    "    for path in catalog[:15]:\n",
    "        print(f\"  {path}\")\n",
    "    \n",
    "    if len(catalog) > 15:\n",
    "        print(f\"  ... and {len(catalog) - 15} more\")\n",
    "else:\n",
    "    print(\"DSS catalog not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Filter Catalog by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    # Filter for different data types\n",
    "    flow_paths = [p for p in catalog if 'FLOW' in p.upper()]\n",
    "    precip_paths = [p for p in catalog if 'PRECIP' in p.upper()]\n",
    "    depth_paths = [p for p in catalog if 'DEPTH' in p.upper()]\n",
    "    \n",
    "    print(\"Pathnames by Data Type:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Flow:          {len(flow_paths)} paths\")\n",
    "    print(f\"  Precipitation: {len(precip_paths)} paths\")\n",
    "    print(f\"  Depth/Stage:   {len(depth_paths)} paths\")\n",
    "    \n",
    "    # Show flow paths\n",
    "    if flow_paths:\n",
    "        print(\"\\nFlow Pathnames:\")\n",
    "        for path in flow_paths[:10]:\n",
    "            print(f\"  {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Read Time Series Data\n",
    "\n",
    "Read individual time series from the DSS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists() and flow_paths:\n",
    "    # Read first flow time series\n",
    "    pathname = flow_paths[0]\n",
    "    print(f\"Reading: {pathname}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = HmsDss.read_timeseries(str(dss_file), pathname)\n",
    "    \n",
    "    print(f\"\\nTime Series Properties:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Time range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"  Units: {df.attrs.get('units', 'N/A')}\")\n",
    "    print(f\"  Data type: {df.attrs.get('data_type', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 values:\")\n",
    "    display(df.head(10))\n",
    "else:\n",
    "    print(\"Time series reading not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Extract Peak Flows (HmsResults)\n",
    "\n",
    "`HmsResults.get_peak_flows()` extracts peak discharge for all flow elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    try:\n",
    "        peaks = HmsResults.get_peak_flows(str(dss_file))\n",
    "        \n",
    "        print(\"Peak Flows:\")\n",
    "        print(\"=\" * 60)\n",
    "        display(peaks)\n",
    "        \n",
    "        # Validate: all peaks should be positive\n",
    "        if not peaks.empty and 'peak_flow' in peaks.columns:\n",
    "            all_positive = (peaks['peak_flow'] > 0).all()\n",
    "            print(f\"\\n[{'OK' if all_positive else 'WARNING'}] All peak flows positive: {all_positive}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract peak flows: {e}\")\n",
    "else:\n",
    "    print(\"Peak flow extraction not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Extract Hydrograph Time Series (HmsResults)\n",
    "\n",
    "`HmsResults.get_outflow_timeseries()` extracts the full hydrograph for a specific element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists() and flow_paths:\n",
    "    # Extract element name from first flow path\n",
    "    # DSS path format: /A/B/C/D/E/F/ where B is typically the element name\n",
    "    parts = flow_paths[0].split('/')\n",
    "    element_name = parts[2] if len(parts) > 2 else None\n",
    "    \n",
    "    if element_name:\n",
    "        print(f\"Extracting hydrograph for: {element_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            hydrograph = HmsResults.get_outflow_timeseries(\n",
    "                str(dss_file),\n",
    "                element_name\n",
    "            )\n",
    "            \n",
    "            if hydrograph is not None and not hydrograph.empty:\n",
    "                print(f\"\\nHydrograph Statistics:\")\n",
    "                print(f\"  Duration: {hydrograph.index.max() - hydrograph.index.min()}\")\n",
    "                print(f\"  Peak: {hydrograph['flow'].max():.2f} CFS\")\n",
    "                print(f\"  Time to peak: {hydrograph['flow'].idxmax()}\")\n",
    "                print(f\"  Mean flow: {hydrograph['flow'].mean():.2f}\")\n",
    "                \n",
    "                display(hydrograph.head(10))\n",
    "            else:\n",
    "                print(f\"No hydrograph data found for {element_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract hydrograph: {e}\")\n",
    "else:\n",
    "    print(\"Hydrograph extraction not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Visualize Hydrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if 'hydrograph' in dir() and hydrograph is not None and not hydrograph.empty:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(hydrograph.index, hydrograph['flow'], 'b-', linewidth=1.5)\n",
    "        ax.fill_between(hydrograph.index, hydrograph['flow'], alpha=0.3)\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Flow (CFS)')\n",
    "        ax.set_title(f\"Hydrograph - {element_name}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark peak\n",
    "        peak_idx = hydrograph['flow'].idxmax()\n",
    "        peak_val = hydrograph['flow'].max()\n",
    "        ax.axhline(y=peak_val, color='r', linestyle='--', alpha=0.5)\n",
    "        ax.annotate(f'Peak: {peak_val:.1f}', \n",
    "                    xy=(peak_idx, peak_val),\n",
    "                    xytext=(10, 10), textcoords='offset points',\n",
    "                    fontsize=10, color='red')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No hydrograph data available for plotting\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed - visualization skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Compare Multiple Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    # Get unique element names from flow paths\n",
    "    elements = set()\n",
    "    for path in flow_paths:\n",
    "        parts = path.split('/')\n",
    "        if len(parts) > 2:\n",
    "            elements.add(parts[2])\n",
    "    \n",
    "    print(f\"Flow elements in DSS ({len(elements)}):\")\n",
    "    print(\"=\" * 60)\n",
    "    for elem in sorted(elements):\n",
    "        print(f\"  {elem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple hydrographs on same figure\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if dss_available and dss_file and dss_file.exists() and len(elements) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        \n",
    "        # Plot up to 5 elements\n",
    "        for i, elem in enumerate(sorted(elements)[:5]):\n",
    "            try:\n",
    "                ts = HmsResults.get_outflow_timeseries(str(dss_file), elem)\n",
    "                if ts is not None and not ts.empty:\n",
    "                    ax.plot(ts.index, ts['flow'], linewidth=1.5, label=elem)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Flow (CFS)')\n",
    "        ax.set_title('Multi-Element Hydrograph Comparison')\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed - visualization skipped\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not create multi-element plot: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dss_available and dss_file and dss_file.exists():\n",
    "    print(\"DSS File Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  File: {dss_file.name}\")\n",
    "    print(f\"  Size: {dss_file.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"  Total pathnames: {len(catalog)}\")\n",
    "    print(f\"  Flow time series: {len(flow_paths)}\")\n",
    "    print(f\"  Precip time series: {len(precip_paths)}\")\n",
    "    print(f\"  Flow elements: {len(elements)}\")\n",
    "    \n",
    "    if 'peaks' in dir() and peaks is not None and not peaks.empty:\n",
    "        print(f\"\\nPeak Flow Summary:\")\n",
    "        print(f\"  Max peak: {peaks['peak_flow'].max():.1f} CFS\")\n",
    "        print(f\"  Min peak: {peaks['peak_flow'].min():.1f} CFS\")\n",
    "        print(f\"  Elements: {len(peaks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated DSS operations and results extraction:\n",
    "\n",
    "| Class | Method | Purpose |\n",
    "|-------|--------|--------|\n",
    "| `HmsDss` | `is_available()` | Check if DSS operations are available |\n",
    "| `HmsDss` | `get_info()` | Get DSS file metadata |\n",
    "| `HmsDss` | `get_catalog()` | List all pathnames in DSS |\n",
    "| `HmsDss` | `read_timeseries()` | Read individual time series |\n",
    "| `HmsResults` | `get_peak_flows()` | Extract peak flows for all elements |\n",
    "| `HmsResults` | `get_outflow_timeseries()` | Extract full hydrograph |\n",
    "\n",
    "**Prerequisites**:\n",
    "- Java 8+ JDK/JRE\n",
    "- `pyjnius` package\n",
    "- HEC Monolith libraries (auto-downloaded)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **07_execution_jython.ipynb**: Advanced execution patterns\n",
    "- **08_m3_models.ipynb**: Work with HCFCD M3 models\n",
    "- **05_clone_workflow.ipynb**: Compare results between scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
