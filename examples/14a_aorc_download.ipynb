{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AORC Download and Storm Catalog\n",
    "\n",
    "This notebook demonstrates how to download AORC (Analysis of Record for Calibration) precipitation data and build storm catalogs for HEC-HMS gridded precipitation modeling.\n",
    "\n",
    "**Workflow Overview**:\n",
    "1. Download HUC12 watersheds as study area templates (HmsHuc)\n",
    "2. Generate storm catalog from AORC data (HmsAorc)\n",
    "3. Download AORC precipitation data for selected storm\n",
    "4. Convert to DSS grid format for HMS\n",
    "\n",
    "**Prerequisites**:\n",
    "- Internet connection (AWS S3 and USGS web services)\n",
    "- Optional dependencies: `pip install hms-commander[all]`\n",
    "\n",
    "**Series Navigation**:\n",
    "- **14a** (this notebook): AORC download and storm catalog\n",
    "- **14b**: HMS grid definition and HRAP mapping\n",
    "- **14c**: HMS execution and results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hms-commander[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Development**: If working on hms-commander source code, use the `hmscmdr_local` conda environment (editable install) instead of pip install.\n",
    "\n",
    "**Network Requirements**: This notebook requires internet access to:\n",
    "- USGS WBD web services (HUC watershed boundaries)\n",
    "- AWS S3 (AORC precipitation data - anonymous access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress warnings and verbose logging for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('botocore').setLevel(logging.WARNING)\n",
    "logging.getLogger('botocore.httpchecksum').setLevel(logging.WARNING)\n",
    "logging.getLogger('s3fs').setLevel(logging.WARNING)\n",
    "logging.getLogger('aiobotocore').setLevel(logging.WARNING)\n",
    "\n",
    "# HMS Commander imports\n",
    "from hms_commander import HmsHuc, HmsAorc, HmsExamples\n",
    "\n",
    "# Create output directory for this workflow\n",
    "output_dir = Path(\"aorc_workflow_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir.absolute()}\")\n",
    "print(f\"Workflow started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Download HUC12 Watersheds\n",
    "\n",
    "We'll use Bald Eagle Creek watershed in Pennsylvania as our study area. HmsHuc downloads HUC boundaries from USGS web services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study area bounds (west, south, east, north)\n",
    "# Bald Eagle Creek, PA - a well-documented watershed\n",
    "bounds = (-77.71, 41.01, -77.25, 41.22)\n",
    "\n",
    "print(\"Study Area: Bald Eagle Creek, PA\")\n",
    "print(f\"  West:  {bounds[0]}deg\")\n",
    "print(f\"  South: {bounds[1]}deg\")\n",
    "print(f\"  East:  {bounds[2]}deg\")\n",
    "print(f\"  North: {bounds[3]}deg\")\n",
    "print(f\"  Width:  {abs(bounds[2] - bounds[0]):.2f}deg (~{abs(bounds[2] - bounds[0]) * 85:.1f} km)\")\n",
    "print(f\"  Height: {abs(bounds[3] - bounds[1]):.2f}deg (~{abs(bounds[3] - bounds[1]) * 111:.1f} km)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download HUC12 watersheds for study area\n",
    "print(\"Downloading HUC12 watersheds from USGS WBD...\")\n",
    "watersheds = HmsHuc.get_huc12_for_bounds(bounds)\n",
    "\n",
    "print(f\"\\nDownloaded {len(watersheds)} HUC12 watersheds\")\n",
    "print(f\"Total area: {watersheds['areasqkm'].sum():.1f} km2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display watershed summary\n",
    "display_cols = ['huc12', 'name', 'areasqkm']\n",
    "watersheds[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get HUC information\nhuc_info = HmsHuc.get_huc_info()\nprint(\"HUC Level Information:\")\nfor level, info in huc_info.items():\n    print(f\"  {level}: {info['description']} (typical size: {info['typical_size']})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Watersheds (Optional)\n",
    "\n",
    "If geopandas and matplotlib are available, visualize the downloaded watersheds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    watersheds.plot(ax=ax, column='areasqkm', cmap='Blues', edgecolor='darkblue',\n",
    "                    linewidth=1, alpha=0.7, legend=True,\n",
    "                    legend_kwds={'label': 'Area (km2)'})\n",
    "    \n",
    "    # Label each watershed\n",
    "    for idx, row in watersheds.iterrows():\n",
    "        centroid = row.geometry.centroid\n",
    "        ax.annotate(row['name'][:15], xy=(centroid.x, centroid.y),\n",
    "                    ha='center', va='center', fontsize=7,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    ax.set_title('Bald Eagle Creek HUC12 Watersheds', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Matplotlib not available - skipping visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: AORC Storm Catalog\n",
    "\n",
    "Generate a catalog of significant storm events from AORC data. This identifies storms with the highest precipitation depths for design storm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AORC dataset information\n",
    "aorc_info = HmsAorc.get_info()\n",
    "print(\"AORC Dataset Information:\")\n",
    "print(f\"  Name: {aorc_info['name']}\")\n",
    "print(f\"  Source: {aorc_info['source']}\")\n",
    "print(f\"  Coverage: {aorc_info['coverage']['spatial']}\")\n",
    "print(f\"  Resolution: {aorc_info['resolution']['spatial']}, {aorc_info['resolution']['temporal']}\")\n",
    "print(f\"  Primary Variable: APCP_surface - {aorc_info['variables']['APCP_surface']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate storm catalog for 2019\n",
    "# Using 2019 as a stable year with good data coverage\n",
    "print(\"Generating storm catalog for 2019...\")\n",
    "print(\"(This may take 30-60 seconds to query AWS S3)\")\n",
    "\n",
    "storms = HmsAorc.get_storm_catalog(bounds, year=2019)\n",
    "\n",
    "if len(storms) > 0:\n",
    "    print(f\"\\nFound {len(storms)} significant storm events\")\n",
    "    print(f\"Total precipitation depth range: {storms['total_depth_in'].min():.2f} - {storms['total_depth_in'].max():.2f} inches\")\n",
    "else:\n",
    "    print(\"\\nNo storms found - trying 2018 as fallback year...\")\n",
    "    storms = HmsAorc.get_storm_catalog(bounds, year=2018)\n",
    "    if len(storms) > 0:\n",
    "        print(f\"Found {len(storms)} significant storm events in 2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 storms by total depth\n",
    "if len(storms) > 0:\n",
    "    display_cols = ['storm_id', 'start_time', 'end_time', 'duration_hours', 'total_depth_in', 'rank']\n",
    "    storms[display_cols].head(10)\n",
    "else:\n",
    "    print(\"No storm data available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storm Catalog Visualization\n",
    "\n",
    "Generate summary visualizations of all storm events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storm catalog summary visualization\n",
    "if len(storms) > 0:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "        # 1. Total depth by storm\n",
    "        ax1 = axes[0, 0]\n",
    "        bars1 = ax1.bar(storms['storm_id'], storms['total_depth_in'], color='steelblue', alpha=0.8)\n",
    "        ax1.set_xlabel('Storm ID')\n",
    "        ax1.set_ylabel('Total Depth (inches)')\n",
    "        ax1.set_title('Precipitation Totals by Storm')\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        # 2. Peak intensity\n",
    "        ax2 = axes[0, 1]\n",
    "        bars2 = ax2.bar(storms['storm_id'], storms['peak_intensity_in_hr'], color='darkorange', alpha=0.8)\n",
    "        ax2.set_xlabel('Storm ID')\n",
    "        ax2.set_ylabel('Peak Intensity (in/hr)')\n",
    "        ax2.set_title('Peak Rainfall Intensity')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        # 3. Duration\n",
    "        ax3 = axes[1, 0]\n",
    "        bars3 = ax3.bar(storms['storm_id'], storms['duration_hours'], color='seagreen', alpha=0.8)\n",
    "        ax3.set_xlabel('Storm ID')\n",
    "        ax3.set_ylabel('Duration (hours)')\n",
    "        ax3.set_title('Storm Duration')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        # 4. Storm timeline\n",
    "        ax4 = axes[1, 1]\n",
    "        for i, (_, storm) in enumerate(storms.iterrows()):\n",
    "            ax4.barh(i, storm['duration_hours'], left=storm['start_time'].dayofyear,\n",
    "                     height=0.6, color='steelblue', alpha=0.7)\n",
    "        ax4.set_yticks(range(len(storms)))\n",
    "        ax4.set_yticklabels(storms['storm_id'])\n",
    "        ax4.set_xlabel('Day of Year')\n",
    "        ax4.set_title('Storm Timeline')\n",
    "        ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "        plt.suptitle('Storm Catalog Summary', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available - skipping visualization\")\n",
    "else:\n",
    "    print(\"No storms available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 3: Download AORC Data\n",
    "\n",
    "Download AORC precipitation data for the selected (largest) storm event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the largest storm for demonstration\n",
    "if len(storms) > 0:\n",
    "    largest_storm = storms[storms['rank'] == 1].iloc[0]\n",
    "\n",
    "    print(\"Selected Storm (Largest):\")\n",
    "    print(f\"  Storm ID: {largest_storm['storm_id']}\")\n",
    "    print(f\"  Start: {largest_storm['start_time']}\")\n",
    "    print(f\"  End: {largest_storm['end_time']}\")\n",
    "    print(f\"  Duration: {largest_storm['duration_hours']} hours\")\n",
    "    print(f\"  Total Depth: {largest_storm['total_depth_in']:.2f} inches\")\n",
    "    print(f\"\\nRecommended Simulation Window:\")\n",
    "    print(f\"  Start: {largest_storm['sim_start']}\")\n",
    "    print(f\"  End: {largest_storm['sim_end']}\")\n",
    "else:\n",
    "    print(\"No storms available - using fixed date range for demonstration\")\n",
    "    # Fallback to a known good period\n",
    "    largest_storm = {\n",
    "        'storm_id': 'FALLBACK_2019',\n",
    "        'sim_start': '2019-06-01',\n",
    "        'sim_end': '2019-06-03',\n",
    "        'total_depth_in': 2.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download AORC data for the storm\n",
    "nc_file = output_dir / \"aorc_storm.nc\"\n",
    "\n",
    "print(f\"Downloading AORC data from AWS S3...\")\n",
    "print(f\"  Bounds: {bounds}\")\n",
    "if hasattr(largest_storm, 'keys'):\n",
    "    print(f\"  Period: {largest_storm['sim_start']} to {largest_storm['sim_end']}\")\n",
    "    sim_start = str(largest_storm['sim_start'])\n",
    "    sim_end = str(largest_storm['sim_end'])\n",
    "else:\n",
    "    print(f\"  Period: {largest_storm.sim_start} to {largest_storm.sim_end}\")\n",
    "    sim_start = str(largest_storm.sim_start)\n",
    "    sim_end = str(largest_storm.sim_end)\n",
    "\n",
    "nc_result = HmsAorc.download(\n",
    "    bounds=bounds,\n",
    "    start_time=sim_start,\n",
    "    end_time=sim_end,\n",
    "    output_path=nc_file\n",
    ")\n",
    "\n",
    "print(f\"\\nDownload complete!\")\n",
    "print(f\"  File: {nc_result}\")\n",
    "print(f\"  Size: {nc_result.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the NetCDF file structure\n",
    "try:\n",
    "    import xarray as xr\n",
    "    \n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    print(\"NetCDF Structure:\")\n",
    "    print(ds)\n",
    "    \n",
    "    # Get grid dimensions\n",
    "    lon_dim = 'longitude' if 'longitude' in ds.dims else 'lon' if 'lon' in ds.dims else 'x'\n",
    "    lat_dim = 'latitude' if 'latitude' in ds.dims else 'lat' if 'lat' in ds.dims else 'y'\n",
    "    time_dim = 'time' if 'time' in ds.dims else 'valid_time'\n",
    "    \n",
    "    print(f\"\\nGrid Dimensions:\")\n",
    "    print(f\"  Longitude: {len(ds[lon_dim])} cells ({float(ds[lon_dim].min()):.4f}deg to {float(ds[lon_dim].max()):.4f}deg)\")\n",
    "    print(f\"  Latitude: {len(ds[lat_dim])} cells ({float(ds[lat_dim].min()):.4f}deg to {float(ds[lat_dim].max()):.4f}deg)\")\n",
    "    print(f\"  Time: {len(ds[time_dim])} timesteps\")\n",
    "    \n",
    "    ds.close()\n",
    "except Exception as e:\n",
    "    print(f\"Could not examine NetCDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 4: Convert to DSS Grid\n",
    "\n",
    "Convert the NetCDF to HMS-compatible DSS grid format using HEC Monolith libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NetCDF to DSS grid\n",
    "dss_file = output_dir / \"aorc_storm.dss\"\n",
    "\n",
    "print(\"Converting to DSS grid format...\")\n",
    "print(\"(Using HEC Monolith via pyjnius)\")\n",
    "\n",
    "dss_result = HmsAorc.convert_to_dss_grid(\n",
    "    netcdf_file=nc_file,\n",
    "    output_dss_file=dss_file,\n",
    "    pathname=\"/AORC/BALDEAGLE/PRECIP////\",\n",
    "    units=\"MM\"\n",
    ")\n",
    "\n",
    "print(f\"\\nConversion complete!\")\n",
    "print(f\"  File: {dss_result}\")\n",
    "print(f\"  Size: {dss_result.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify DSS file (optional - requires ras-commander DSS support)\n",
    "try:\n",
    "    from ras_commander.dss import RasDss\n",
    "    \n",
    "    catalog = RasDss.get_catalog(str(dss_file))\n",
    "    print(f\"DSS Catalog: {len(catalog)} records\")\n",
    "    print(f\"\\nSample pathnames:\")\n",
    "    for path in catalog[:5]:\n",
    "        print(f\"  {path}\")\n",
    "    if len(catalog) > 5:\n",
    "        print(f\"  ... and {len(catalog) - 5} more\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read DSS catalog: {e}\")\n",
    "    print(\"(This is normal if ras-commander is not installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Downloading HUC12 watershed boundaries using HmsHuc\n",
    "2. Generating storm catalogs from AORC data using HmsAorc\n",
    "3. Downloading AORC precipitation data for a selected storm\n",
    "4. Converting to DSS grid format for HMS\n",
    "\n",
    "**Output Files Created**:\n",
    "- `aorc_storm.nc` - NetCDF precipitation data\n",
    "- `aorc_storm.dss` - DSS grid for HMS\n",
    "\n",
    "**Next Steps**:\n",
    "- Continue to **14b_aorc_grid_setup.ipynb** to create HMS grid definition and cell mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of outputs\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1-2 COMPLETE: AORC DOWNLOAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nStudy Area: Bald Eagle Creek, PA\")\n",
    "print(f\"  Bounds: {bounds}\")\n",
    "print(f\"  HUC12 watersheds: {len(watersheds)}\")\n",
    "print(f\"  Total area: {watersheds['areasqkm'].sum():.1f} km2\")\n",
    "\n",
    "if len(storms) > 0:\n",
    "    if hasattr(largest_storm, 'keys'):\n",
    "        total_depth = largest_storm['total_depth_in']\n",
    "    else:\n",
    "        total_depth = largest_storm.total_depth_in\n",
    "    print(f\"\\nSelected Storm:\")\n",
    "    print(f\"  Total depth: {total_depth:.2f} inches\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "for f in sorted(output_dir.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        print(f\"  {f.name}: {f.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(f\"\\nWorkflow completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n--> Continue to 14b_aorc_grid_setup.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}