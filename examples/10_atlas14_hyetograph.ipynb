{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas 14 Hyetograph Generation\n",
    "\n",
    "This notebook demonstrates how to generate design storm hyetographs using NOAA Atlas 14 temporal distributions with the `Atlas14Storm` module.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Generate design storm hyetographs for HMS and RAS **without requiring HEC-HMS execution**, using the same Atlas 14 temporal distributions that HEC-HMS uses internally.\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "1. Configure Atlas14Storm for a specific region and duration\n",
    "2. Generate hyetographs with depth conservation verification\n",
    "3. Work with DDF (Depth-Duration-Frequency) tables\n",
    "4. Visualize and export hyetographs for downstream use\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Internet connection (for NOAA data download on first use)\n",
    "- Understanding of design storm concepts (AEP, DDF tables)\n",
    "\n",
    "## Related Notebooks\n",
    "\n",
    "- **Notebook 11** (FrequencyStorm): Variable duration storms using TP-40 patterns\n",
    "- **Notebook 13** (Validation): Multi-duration validation with detailed equivalence proofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hms-commander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Development**: If working on hms-commander source code, use the `hmscmdr_local` conda environment (editable install) instead of pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hms_commander import Atlas14Storm\n",
    "\n",
    "print(\"Atlas14Storm module loaded\")\n",
    "print(f\"Supported durations: {Atlas14Storm.SUPPORTED_DURATIONS} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Atlas 14 Configuration\n",
    "\n",
    "Atlas 14 data is organized by state, region, and duration. This example uses Houston, TX (Region 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houston, TX - Atlas 14 Volume 11, Region 3\n",
    "STATE = \"tx\"\n",
    "REGION = 3\n",
    "DURATION_HOURS = 24\n",
    "\n",
    "print(\"Atlas 14 Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Location: Houston, TX\")\n",
    "print(f\"  State Code: {STATE}\")\n",
    "print(f\"  Region: {REGION}\")\n",
    "print(f\"  Duration: {DURATION_HOURS} hours\")\n",
    "print(f\"\\nData Source: NOAA Precipitation Frequency Data Server\")\n",
    "print(f\"URL: https://hdsc.nws.noaa.gov/pub/hdsc/data/{STATE}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DDF Table (Depth-Duration-Frequency)\n",
    "\n",
    "A DDF table provides total precipitation depths for various return periods (AEP = Annual Exceedance Probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DDFEntry:\n",
    "    \"\"\"Depth-Duration-Frequency table entry.\"\"\"\n",
    "    ari_years: int      # Average Recurrence Interval (years)\n",
    "    aep_percent: float  # Annual Exceedance Probability (%)\n",
    "    depth_inches: float # Total precipitation depth (inches)\n",
    "    \n",
    "    @property\n",
    "    def ari_str(self) -> str:\n",
    "        return f\"{self.ari_years}-year\"\n",
    "    \n",
    "    @property\n",
    "    def aep_str(self) -> str:\n",
    "        return f\"{self.aep_percent}\"\n",
    "\n",
    "# Houston, TX - Atlas 14 24-hour DDF values\n",
    "DDF_TABLE = [\n",
    "    DDFEntry(ari_years=2, aep_percent=50.0, depth_inches=5.00),\n",
    "    DDFEntry(ari_years=5, aep_percent=20.0, depth_inches=6.80),\n",
    "    DDFEntry(ari_years=10, aep_percent=10.0, depth_inches=8.30),\n",
    "    DDFEntry(ari_years=25, aep_percent=4.0, depth_inches=10.90),\n",
    "    DDFEntry(ari_years=50, aep_percent=2.0, depth_inches=13.30),\n",
    "    DDFEntry(ari_years=100, aep_percent=1.0, depth_inches=17.90),\n",
    "    DDFEntry(ari_years=200, aep_percent=0.5, depth_inches=19.70),\n",
    "    DDFEntry(ari_years=500, aep_percent=0.2, depth_inches=22.80),\n",
    "]\n",
    "\n",
    "print(\"Houston, TX - 24-Hour DDF Table (Atlas 14)\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'ARI':>10} {'AEP (%)':>10} {'Depth (in)':>12}\")\n",
    "print(\"-\" * 55)\n",
    "for entry in DDF_TABLE:\n",
    "    print(f\"{entry.ari_str:>10} {entry.aep_percent:>10.1f} {entry.depth_inches:>12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Hyetographs\n",
    "\n",
    "Generate hyetographs for all AEP events using `Atlas14Storm.generate_hyetograph()`.\n",
    "\n",
    "The function returns a DataFrame with columns:\n",
    "- `hour`: Time in hours from storm start\n",
    "- `incremental_depth`: Precipitation depth in each interval (inches)\n",
    "- `cumulative_depth`: Running total precipitation (inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating hyetographs for all DDF entries...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "hyetographs = {}\n",
    "\n",
    "for entry in DDF_TABLE:\n",
    "    # Generate hyetograph\n",
    "    hyeto = Atlas14Storm.generate_hyetograph(\n",
    "        total_depth_inches=entry.depth_inches,\n",
    "        state=STATE,\n",
    "        region=REGION,\n",
    "        duration_hours=DURATION_HOURS,\n",
    "        aep_percent=entry.aep_percent,\n",
    "        quartile=\"All Cases\"  # Median temporal pattern\n",
    "    )\n",
    "    \n",
    "    hyetographs[entry.ari_str] = hyeto\n",
    "    \n",
    "    # Statistics\n",
    "    total = hyeto['cumulative_depth'].iloc[-1]\n",
    "    peak = hyeto['incremental_depth'].max()\n",
    "    peak_idx = hyeto['incremental_depth'].idxmax()\n",
    "    peak_time = hyeto['hour'].iloc[peak_idx]\n",
    "    \n",
    "    # Verify total depth conservation\n",
    "    diff = abs(total - entry.depth_inches)\n",
    "    status = \"PASS\" if diff < 0.001 else \"FAIL\"\n",
    "    \n",
    "    print(f\"{entry.ari_str:>10}: {len(hyeto)} intervals, \"\n",
    "          f\"total={total:.3f} in, peak={peak:.3f} in @ {peak_time:.1f}h [{status}]\")\n",
    "\n",
    "print(\"\\nAll hyetographs generated and verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Hyetographs\n",
    "\n",
    "Compare hyetograph shapes across different return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Select 4 storms for visualization\n",
    "storms_to_plot = ['10-year', '50-year', '100-year', '500-year']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for ax, storm_name, color in zip(axes.flat, storms_to_plot, colors):\n",
    "    hyeto = hyetographs[storm_name]\n",
    "    \n",
    "    ax.bar(hyeto['hour'], hyeto['incremental_depth'], \n",
    "           width=0.45, color=color, alpha=0.7, edgecolor='navy')\n",
    "    \n",
    "    # Peak annotation\n",
    "    peak_idx = hyeto['incremental_depth'].idxmax()\n",
    "    peak_time = hyeto['hour'].iloc[peak_idx]\n",
    "    peak_depth = hyeto['incremental_depth'].max()\n",
    "    total = hyeto['cumulative_depth'].iloc[-1]\n",
    "    \n",
    "    ax.annotate(f'Peak: {peak_depth:.2f}\"\\n@ {peak_time:.1f}h',\n",
    "                xy=(peak_time, peak_depth),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=9, color='red',\n",
    "                arrowprops=dict(arrowstyle='->', color='red'))\n",
    "    \n",
    "    ax.set_xlabel('Time (hours)')\n",
    "    ax.set_ylabel('Precipitation (inches/30min)')\n",
    "    ax.set_title(f'{storm_name} Storm ({total:.1f}\" total)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(0, 24)\n",
    "\n",
    "plt.suptitle('Atlas 14 Hyetographs - Houston, TX (Region 3)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cumulative Distribution Comparison\n",
    "\n",
    "The temporal pattern is the same for all return periods - only the total depth changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for storm_name in ['10-year', '50-year', '100-year', '500-year']:\n",
    "    hyeto = hyetographs[storm_name]\n",
    "    \n",
    "    # Normalize to percentage\n",
    "    time_pct = hyeto['hour'] / 24 * 100\n",
    "    cumulative_pct = hyeto['cumulative_depth'] / hyeto['cumulative_depth'].iloc[-1] * 100\n",
    "    \n",
    "    ax.plot(time_pct, cumulative_pct, '-', linewidth=2, label=storm_name)\n",
    "\n",
    "ax.set_xlabel('Time (% of storm duration)', fontsize=12)\n",
    "ax.set_ylabel('Cumulative Precipitation (%)', fontsize=12)\n",
    "ax.set_title('Normalized Cumulative Distribution - All Return Periods', fontsize=14)\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: All curves overlap because the temporal distribution is identical.\")\n",
    "print(\"Only the total depth (scaling factor) differs between return periods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Working with Quartiles\n",
    "\n",
    "Atlas 14 provides 5 quartile options that control the timing of peak intensity:\n",
    "- **First Quartile**: Early peak (conservative for upstream flooding)\n",
    "- **Second Quartile**: Early-to-median peak\n",
    "- **Third Quartile**: Median-to-late peak\n",
    "- **Fourth Quartile**: Late peak (conservative for downstream flooding)\n",
    "- **All Cases**: Median temporal pattern (most common choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare quartiles for 100-year storm\n",
    "quartiles = ['First Quartile', 'Second Quartile', 'Third Quartile', 'Fourth Quartile', 'All Cases']\n",
    "depth_100yr = 17.90\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "print(\"100-year Storm - Quartile Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for quartile in quartiles:\n",
    "    hyeto = Atlas14Storm.generate_hyetograph(\n",
    "        total_depth_inches=depth_100yr,\n",
    "        state=STATE,\n",
    "        region=REGION,\n",
    "        duration_hours=24,\n",
    "        aep_percent=1.0,\n",
    "        quartile=quartile\n",
    "    )\n",
    "    \n",
    "    peak_idx = hyeto['incremental_depth'].idxmax()\n",
    "    peak_time = hyeto['hour'].iloc[peak_idx]\n",
    "    peak_depth = hyeto['incremental_depth'].max()\n",
    "    \n",
    "    print(f\"{quartile:>16}: peak={peak_depth:.2f} in @ {peak_time:.1f}h\")\n",
    "    \n",
    "    ax.plot(hyeto['hour'], hyeto['cumulative_depth'], '-', linewidth=2, label=quartile)\n",
    "\n",
    "ax.set_xlabel('Time (hours)')\n",
    "ax.set_ylabel('Cumulative Precipitation (inches)')\n",
    "ax.set_title('100-year Storm - Quartile Comparison')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export for HEC-RAS\n",
    "\n",
    "Generate a hyetograph for use as a HEC-RAS boundary condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate 100-year storm for RAS\n",
    "hyeto_100yr = Atlas14Storm.generate_hyetograph(\n",
    "    total_depth_inches=17.90,\n",
    "    state=\"tx\",\n",
    "    region=3,\n",
    "    duration_hours=24,\n",
    "    aep_percent=1.0,\n",
    "    quartile=\"All Cases\"\n",
    ")\n",
    "\n",
    "# Create timestamp-indexed DataFrame for RAS\n",
    "start_time = pd.Timestamp('2024-01-01 00:00:00')\n",
    "hyeto_100yr['datetime'] = pd.date_range(\n",
    "    start=start_time, \n",
    "    periods=len(hyeto_100yr), \n",
    "    freq='30min'\n",
    ")\n",
    "\n",
    "print(\"100-year Hyetograph for HEC-RAS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Depth: {hyeto_100yr['cumulative_depth'].iloc[-1]:.3f} inches\")\n",
    "print(f\"Time Steps: {len(hyeto_100yr)}\")\n",
    "print(f\"Interval: 30 minutes\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(hyeto_100yr[['datetime', 'hour', 'incremental_depth', 'cumulative_depth']].head(10).to_string(index=False))\n",
    "\n",
    "# Export to CSV\n",
    "output_file = Path('atlas14_100yr_24hr.csv')\n",
    "hyeto_100yr[['datetime', 'incremental_depth']].to_csv(output_file, index=False)\n",
    "print(f\"\\nExported to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Capabilities\n",
    "\n",
    "**Atlas14Storm generates design storm hyetographs WITHOUT HEC-HMS**:\n",
    "- Uses official NOAA Atlas 14 temporal distributions\n",
    "- Implements same algorithm as HEC-HMS \"Specified Pattern\"\n",
    "- Guaranteed total depth conservation\n",
    "- Supports all Atlas 14 quartiles\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "from hms_commander import Atlas14Storm\n",
    "\n",
    "hyeto = Atlas14Storm.generate_hyetograph(\n",
    "    total_depth_inches=17.9,  # From Atlas 14 DDF table\n",
    "    state=\"tx\",\n",
    "    region=3,\n",
    "    duration_hours=24,\n",
    "    aep_percent=1.0,          # 100-year storm\n",
    "    quartile=\"All Cases\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Available Durations\n",
    "\n",
    "NOAA provides temporal distributions for: **6h, 12h, 24h, 96h**\n",
    "\n",
    "**Note**: 48-hour is NOT available from NOAA. Use `FrequencyStorm` for 48-hour storms.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Notebook 11**: FrequencyStorm for variable duration storms\n",
    "- **Notebook 13**: Multi-duration validation with equivalence proofs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
